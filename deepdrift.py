# -*- coding: utf-8 -*-
"""DeepDrift.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CRCTVIWh8DIWViHdQYhOMgTTXU0wCYoq
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# --- CONFIGURATION ---
np.random.seed(42)
tf.random.set_seed(42)
plt.style.use('ggplot') # Professional style

# ==========================================
# 1. SOPHISTICATED DATA GENERATION
# ==========================================
print("Generating Telemetry...")
n_normal = 5000
n_attack = 200

# Normal Behavior (The Baseline)
normal_data = {
    'File_Entropy': np.random.normal(4.0, 0.5, n_normal),    # Standard files
    'Process_CPU': np.random.normal(10, 5, n_normal),        # Idle/Low usage
    'Network_Bytes': np.random.exponential(500, n_normal),   # Browsing
    'Login_Count': np.random.poisson(2, n_normal),           # Few logins
    'label': 0
}

# Attack 1: Ransomware (High Entropy + High CPU)
ransomware_data = {
    'File_Entropy': np.random.normal(7.9, 0.1, n_attack),    # Encrypted!
    'Process_CPU': np.random.normal(90, 5, n_attack),        # Encryption load
    'Network_Bytes': np.random.exponential(200, n_attack),   # Local activity
    'Login_Count': np.random.poisson(2, n_attack),
    'label': 1
}

# Attack 2: Insider Exfiltration (Massive Network + Odd Logins)
exfil_data = {
    'File_Entropy': np.random.normal(4.0, 0.5, n_attack),
    'Process_CPU': np.random.normal(30, 10, n_attack),
    'Network_Bytes': np.random.normal(50000, 5000, n_attack), # Huge Upload
    'Login_Count': np.random.normal(20, 5, n_attack),         # Brute force/spam
    'label': 1
}

# Combine
df = pd.concat([
    pd.DataFrame(normal_data),
    pd.DataFrame(ransomware_data),
    pd.DataFrame(exfil_data)
])
df = df.sample(frac=1).reset_index(drop=True)

# ==========================================
# 2. PREPROCESSING
# ==========================================
features = ['File_Entropy', 'Process_CPU', 'Network_Bytes', 'Login_Count']
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(df[features])
y = df['label']

# Split: Train ONLY on Normal data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
X_train_normal = X_train[y_train == 0]

# ==========================================
# 3. AUTOENCODER MODEL (TRAINING)
# ==========================================
print("Training Deep Autoencoder...")
input_dim = X_train_normal.shape[1]

input_layer = Input(shape=(input_dim,))
encoder = Dense(8, activation="relu")(input_layer) # Compression
decoder = Dense(input_dim, activation="sigmoid")(encoder) # Reconstruction

autoencoder = Model(inputs=input_layer, outputs=decoder)
autoencoder.compile(optimizer='adam', loss='mse')

history = autoencoder.fit(
    X_train_normal, X_train_normal,
    epochs=40, batch_size=64, validation_split=0.1, verbose=0
)

# ==========================================
# 4. DRIFT DETECTION & EXPLAINABILITY
# ==========================================
print("Analyzing Drift & Features...")

# A. Reconstruction
reconstructions = autoencoder.predict(X_test)

# B. Calculate Error per Feature (squared difference)
# This is the "Why" - which feature failed to reconstruct?
feature_errors = np.power(X_test - reconstructions, 2)

# C. Calculate Total MSE per Row
mse = np.mean(feature_errors, axis=1)

# D. Dynamic Threshold (95th percentile of errors)
threshold = np.percentile(mse, 95)
y_pred = [1 if e > threshold else 0 for e in mse]

# ==========================================
# 5. ULTIMATE DASHBOARD
# ==========================================
fig = plt.figure(figsize=(18, 10))
gs = fig.add_gridspec(2, 2)

# PLOT 1: The Signal (Error Distribution)
ax1 = fig.add_subplot(gs[0, 0])
sns.histplot(mse[y_test==0], bins=50, kde=True, color='blue', label='Normal', alpha=0.6, ax=ax1)
sns.histplot(mse[y_test==1], bins=50, kde=True, color='red', label='Attack', alpha=0.6, ax=ax1)
ax1.axvline(threshold, color='k', linestyle='--', label=f'Threshold ({threshold:.3f})')
ax1.set_title('Drift Signal (Reconstruction Error)')
ax1.set_xlabel('Mean Squared Error')
ax1.legend()

# PLOT 2: The Performance (ROC Curve)
ax2 = fig.add_subplot(gs[0, 1])
fpr, tpr, _ = roc_curve(y_test, mse)
roc_auc = auc(fpr, tpr)
ax2.plot(fpr, tpr, color='darkorange', lw=3, label=f'AUC = {roc_auc:.2f}')
ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
ax2.set_title('Model Accuracy (ROC-AUC)')
ax2.set_xlabel('False Positive Rate')
ax2.set_ylabel('True Positive Rate')
ax2.legend(loc="lower right")

# PLOT 3: The Explanation (Feature Contribution)
# We take the flagged attacks and calculate which feature had the highest error
ax3 = fig.add_subplot(gs[1, :]) # Spans both columns at bottom

# Filter only the correctly detected attacks (True Positives)
true_positives_idx = (np.array(y_pred) == 1) & (np.array(y_test) == 1)
if np.sum(true_positives_idx) > 0:
    tp_errors = feature_errors[true_positives_idx]

    # Calculate average contribution of each feature to the error
    avg_contribution = np.mean(tp_errors, axis=0)

    # Normalize for percentage view
    total_error = np.sum(avg_contribution)
    percentages = (avg_contribution / total_error) * 100

    sns.barplot(x=features, y=percentages, palette='viridis', ax=ax3)
    ax3.set_title('Explainable AI: Why were attacks flagged? (Feature Contribution %)')
    ax3.set_ylabel('Contribution to Drift Score (%)')

    # Add percentage labels on bars
    for i, p in enumerate(percentages):
        ax3.text(i, p + 1, f'{p:.1f}%', ha='center', fontweight='bold')
else:
    ax3.text(0.5, 0.5, "No Attacks Detected (Check Threshold)", ha='center')

plt.tight_layout()
plt.show()

# Final Metrics
print("\n" + "="*30)
print("FINAL RESULTS")
print("="*30)
print(classification_report(y_test, y_pred, target_names=['Safe', 'Drift/Attack']))